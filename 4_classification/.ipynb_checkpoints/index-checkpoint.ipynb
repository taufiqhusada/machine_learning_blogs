{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning Classification Algorithm using Titanic Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog we will learn some classfication algorithm using the famous titanic dataset\n",
    "<ul>\n",
    "<li> dataset: https://www.kaggle.com/competitions/titanic/data </li>\n",
    "<li> task: build a predictive model that predict whether a person survive in the titanic insident based on several factors (e.g., name, age, cabin, etc.) </li>\n",
    "</ul>\n",
    "We will learn some basic data exploration technique, feature engineering, and classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Lets see the preview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some pattern on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df_train['Sex'], y=df_train['Survived']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above we can see that female are much more likely to survive compared to men\n",
    "\n",
    "Now let's find the correlation among the features on the data using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.corr(),annot=True) \n",
    "fig=plt.gcf()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the heatmap above we can see that \"PClass\" and \"Fare\" is highly correlated to the \"Survived\" column, whereas other column is not highly correlated with \"Survived\" column. <br>\n",
    "But since \"Fare\" also highly correlated with \"PClass\" then we just need \"PClass\" column\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Based on our data exploration above we will only use column \"Sex\" and \"PClass\" to predict the survival of each person since those two features are highly correlated with the survival\n",
    "\n",
    "So here is the step of feature engineering that we will do:\n",
    "\n",
    "1. Convert \"Sex\" column into a 0/1 valued column since this column has a categorical data (\"female/male\"). We can call this column \"IsMale\"\n",
    "2. Create new column TicketFreq based on column Ticket. Will explain about this later\n",
    "3. Drop columns other unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column \"IsMale\"\n",
    "\n",
    "df_train_transformed = df_train.copy()\n",
    "df_train_transformed[\"IsMale\"] = df_train[\"Sex\"].apply(lambda x: x == \"male\")\n",
    "df_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticket Frequency is a ticket-based feature that includes people who have the same ticket number. This feature can serve as group size as it puts people who travel with the same ticket number together, whether they are related or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed['TicketFreq'] = df_train.groupby('Ticket')['Ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unwanted columns\n",
    "df_train_transformed = df_train_transformed.drop(['PassengerId','Ticket', 'Sex', 'Name', 'Fare', 'Age', 'Parch', 'SibSp','Cabin', 'Embarked'], axis=1) \n",
    "df_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to do the same feature engineering process on the test dataset, so let's wrap all the process into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, is_train_dataset = True):\n",
    "    df_transformed = df.copy()\n",
    "    df_transformed[\"IsMale\"] = df[\"Sex\"].apply(lambda x: x == \"male\")\n",
    "    \n",
    "    df_transformed['TicketFreq'] = df_train.groupby('Ticket')['Ticket'].transform('count')\n",
    "    \n",
    "    df_transformed = df_transformed.drop(['Ticket', 'Sex', 'Name', 'Fare', 'Age', 'Parch', 'SibSp','Cabin', 'Embarked'], axis=1) \n",
    "    \n",
    "    if (is_train_dataset):\n",
    "        df_transformed = df_transformed.drop(['PassengerId'],axis=1)\n",
    "    \n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = transform_data(df_train)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='IsMale', y='Survived', data=temp_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='TicketFreq', y='Survived', data=temp_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=temp_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "In this part we will experiment with several classifier model\n",
    "\n",
    "To measure performance we will split the training data into `train` and `test`. So we will not touch the real `test` dataset to measure performance during our training process, this is to prevent data test leak. We will use 80/20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['IsMale', 'Pclass', 'TicketFreq']\n",
    "label = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = transform_data(df_train)\n",
    "\n",
    "X = df_train_transformed[predictors]\n",
    "y = df_train_transformed[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, predictions))\n",
    "print('Precision:', metrics.precision_score(y_test,predictions))\n",
    "print('Recall:', metrics.recall_score(y_test, predictions))\n",
    "print('F1:', metrics.f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', metrics.accuracy_score(y_test, predictions))\n",
    "print('Precision:', metrics.precision_score(y_test,predictions))\n",
    "print('Recall:', metrics.recall_score(y_test, predictions))\n",
    "print('F1:', metrics.f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the comparison above, random forest classifier model gives better accuracy, that is why we will choose this model for our final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transformed = transform_data(df_test)\n",
    "X_test_submission = df_test_transformed[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= pd.DataFrame (pd.DataFrame({\n",
    "    \"PassengerId\": df_test[\"PassengerId\"],\n",
    "    \"Survived\": predictions}))\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('FinalSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the result when we submit this to kaggle competition\n",
    "![image](pict/Screenshot_result.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
